{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import  array_to_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 43\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 5\n",
    "# Размер изображений\n",
    "img_rows, img_cols = 48, 48\n",
    "# Количество каналов в изображении: RGB\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    with Image.open(path) as img:\n",
    "        img = img.resize((img_rows, img_cols))\n",
    "        imgarray = numpy.asarray(img)\n",
    "        #mask = numpy.array([[1,1,1]])\n",
    "        #imgarray = imgarray * mask\n",
    "        #print(imgarray.shape)\n",
    "        #imgarray = imgarray.reshape((img_rows, img_cols, img_channels))\n",
    "        #print(imgarray)\n",
    "        return imgarray\n",
    "\n",
    "        \n",
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-' + format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        gtReader.__next__() # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            imgarray = load_img(prefix + row[0])\n",
    "            images.append(imgarray) # the 1th column is the filename             \n",
    "#             images.append(plt.imread(prefix + row[0]))\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26640 26640\n"
     ]
    }
   ],
   "source": [
    "trainImages, trainLabels = readTrafficSigns('C:/Users/tonym/YandexDisk/python/CRT_testing_work/GTSRB/Training')\n",
    "X_train = numpy.asarray(trainImages)/255\n",
    "Y_train = np_utils.to_categorical(trainLabels, nb_classes)\n",
    "print(len(trainLabels), len(trainImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# вариант с генератором "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(100, (7, 7), padding='same', input_shape=(img_rows, img_cols, img_channels), activation='relu'))\n",
    "\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(150, (4, 4), activation='relu', padding='same'))\n",
    "\n",
    "# второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(250, (4, 4), padding='same', activation='relu'))\n",
    "\n",
    "# Третий слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С генератором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "96s - loss: 1.7401 - acc: 0.4874\n",
      "Epoch 2/5\n",
      "77s - loss: 0.3719 - acc: 0.8846\n",
      "Epoch 3/5\n",
      "75s - loss: 0.1925 - acc: 0.9418\n",
      "Epoch 4/5\n",
      "76s - loss: 0.1434 - acc: 0.9575\n",
      "Epoch 5/5\n",
      "75s - loss: 0.1074 - acc: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208bed36d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "              epochs=nb_epoch,steps_per_epoch = 1000,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сохранение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "json_file = open(\"./sample_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"./sample_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_file = open(\"C:/Users/tonym/YandexDisk/python/CRT_testing_work/all_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# Создаем модель\n",
    "model = model_from_json(loaded_model_json)\n",
    "# Загружаем сохраненные веса в модель\n",
    "model.load_weights(\"C:/Users/tonym/YandexDisk/python/CRT_testing_work/all_model.h5\")\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# старое тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность работы загруженной сети на обучающей выборке: 72.83%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"Точность работы загруженной сети на обучающей выборке: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630 12630\n",
      "Точность работы загруженной сети на тестовых данных: 68.61%\n"
     ]
    }
   ],
   "source": [
    "def readTrafficSigns_test(rootpath):\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    prefix = rootpath\n",
    "    gtFile = open(prefix + 'GT-final_test.csv') # annotations file\n",
    "    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "    gtReader.__next__() # skip header\n",
    "    # loop over all images in current annotations file\n",
    "    for row in gtReader:\n",
    "        imgarray = load_img(prefix + row[0])\n",
    "        images.append(imgarray) # the 1th column is the filename             \n",
    "#         images.append(plt.imread(prefix + row[0]))\n",
    "        labels.append(row[7]) # the 8th column is the label\n",
    "    gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "tImages, tLabels = readTrafficSigns_test('./GTSRB_Final_Test_Images/GTSRB/Final_Test/Images/')\n",
    "X_t = numpy.asarray(tImages)/255\n",
    "Y_t = np_utils.to_categorical(tLabels, nb_classes)\n",
    "print(len(tLabels), len(tImages))\n",
    "scores = model.evaluate(X_t, Y_t, verbose=0)\n",
    "print(\"Точность работы загруженной сети на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
