{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import  array_to_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Размер мини-выборки\n",
    "batch_size = 32\n",
    "# Количество классов изображений\n",
    "nb_classes = 43\n",
    "# Количество эпох для обучения\n",
    "nb_epoch = 5\n",
    "# Размер изображений\n",
    "img_rows, img_cols = 48, 48\n",
    "# Количество каналов в изображении: RGB\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# функция загрузки обучающей выборки 2012 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    with Image.open(path) as img:\n",
    "        img = img.resize((img_rows, img_cols))\n",
    "        imgarray = numpy.asarray(img)\n",
    "        #mask = numpy.array([[1,1,1]])\n",
    "        #imgarray = imgarray * mask\n",
    "        #print(imgarray.shape)\n",
    "        #imgarray = imgarray.reshape((img_rows, img_cols, img_channels))\n",
    "        #print(imgarray)\n",
    "        return imgarray\n",
    "\n",
    "        \n",
    "def readTrafficSigns(rootpath):\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-' + format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        gtReader.__next__() # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            imgarray = load_img(prefix + row[0])\n",
    "            images.append(imgarray) # the 1th column is the filename             \n",
    "#             images.append(plt.imread(prefix + row[0]))\n",
    "            labels.append(row[7]) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26640 26640\n"
     ]
    }
   ],
   "source": [
    "trainImages, trainLabels = readTrafficSigns('./GTSRB/Training')\n",
    "X_train = numpy.asarray(trainImages)/255\n",
    "Y_train = np_utils.to_categorical(trainLabels, nb_classes)\n",
    "#print(len(trainLabels), len(trainImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# создания  генератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "# Первый сверточный слой\n",
    "model.add(Conv2D(100, (7, 7), padding='same', input_shape=(img_rows, img_cols, img_channels), activation='relu'))\n",
    "\n",
    "# Первый слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Второй сверточный слой\n",
    "model.add(Conv2D(150, (4, 4), activation='relu', padding='same'))\n",
    "\n",
    "# второй слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Третий сверточный слой\n",
    "model.add(Conv2D(250, (4, 4), padding='same', activation='relu'))\n",
    "\n",
    "# Третий слой подвыборки\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой преобразования данных из 2D представления в плоское\n",
    "model.add(Flatten())\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "# Выходной полносвязный слой\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обучение с генератором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80s - loss: 1.7454 - acc: 0.4850\n",
      "Epoch 2/5\n",
      "77s - loss: 0.3984 - acc: 0.8778\n",
      "Epoch 3/5\n",
      "79s - loss: 0.2036 - acc: 0.9412\n",
      "Epoch 4/5\n",
      "78s - loss: 0.1486 - acc: 0.9578\n",
      "Epoch 5/5\n",
      "77s - loss: 0.1014 - acc: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257ac387d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "              epochs=nb_epoch,steps_per_epoch = 1000,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# дополнительное обучение на тестовых данных 2013г"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 767 samples, validate on 86 samples\n",
      "Epoch 1/5\n",
      "2s - loss: 0.4012 - acc: 0.8931 - val_loss: 0.4075 - val_acc: 0.8837\n",
      "Epoch 2/5\n",
      "1s - loss: 0.0997 - acc: 0.9765 - val_loss: 0.4254 - val_acc: 0.8953\n",
      "Epoch 3/5\n",
      "1s - loss: 0.0333 - acc: 0.9935 - val_loss: 0.3161 - val_acc: 0.8837\n",
      "Epoch 4/5\n",
      "1s - loss: 0.0141 - acc: 0.9987 - val_loss: 0.5152 - val_acc: 0.8721\n",
      "Epoch 5/5\n",
      "1s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.4446 - val_acc: 0.8721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x257c02965c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_13 = [] # images\n",
    "Y_13 = [] # corresponding labels\n",
    "for i in range(43):\n",
    "    prefix = './TrainIJCNN2013/' + format(i, '02d') + '/' # subdirectory for class\n",
    "    j = 0\n",
    "    while True:\n",
    "        try:  \n",
    "            imgarray = load_img(prefix + format(j,\"05d\") +'.ppm')\n",
    "            \n",
    "            #plt.imshow(imgarray)\n",
    "            #plt.show()\n",
    "            X_13.append(imgarray) # the 1th column is the filename\n",
    "            Y_13.append(i)\n",
    "        except IOError as e:\n",
    "            break\n",
    "        j+=1\n",
    "\n",
    "# print(X_test)\n",
    "X_13 = numpy.asarray(X_13)\n",
    "X_13 = X_13.astype('float32')\n",
    "X_13 /= 255\n",
    "Y_13 = np_utils.to_categorical(Y_13, nb_classes)\n",
    "model.fit(X_13, Y_13,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сохранение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "json_file = open(\"./all_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"./all_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загрузка\n",
    "# json_file = open(\"./all_model.json\", \"r\")\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# # Создаем модель\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# # Загружаем сохраненные веса в модель\n",
    "# model.load_weights(\"./all_model.h5\")\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=sgd,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность работы загруженной сети на обучающей выборке: 96.69%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"Точность работы загруженной сети на обучающей выборке: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630 12630\n",
      "Точность работы загруженной сети на тестовых данных: 91.53%\n"
     ]
    }
   ],
   "source": [
    "def readTrafficSigns_test(rootpath):\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    prefix = rootpath\n",
    "    gtFile = open(prefix + 'GT-final_test.csv') # annotations file\n",
    "    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "    gtReader.__next__() # skip header\n",
    "    # loop over all images in current annotations file\n",
    "    for row in gtReader:\n",
    "        imgarray = load_img(prefix + row[0])\n",
    "        images.append(imgarray) # the 1th column is the filename             \n",
    "#         images.append(plt.imread(prefix + row[0]))\n",
    "        labels.append(row[7]) # the 8th column is the label\n",
    "    gtFile.close()\n",
    "    return images, labels\n",
    "\n",
    "tImages, tLabels = readTrafficSigns_test('./GTSRB_Final_Test_Images/GTSRB/Final_Test/Images/')\n",
    "X_t = numpy.asarray(tImages)/255\n",
    "Y_t = np_utils.to_categorical(tLabels, nb_classes)\n",
    "print(len(tLabels), len(tImages))\n",
    "scores = model.evaluate(X_t, Y_t, verbose=0)\n",
    "print(\"Точность работы загруженной сети на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
